{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcqTrBZfSTsL"
      },
      "source": [
        "CODE I EXECUTED FOR STEP 1 AND STEP 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aG_P-2-hpuiP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from selenium import webdriver\n",
        "import urllib.request\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "import regex as re\n",
        "import requests\n",
        "\n",
        "import time\n",
        "# Initialize the driver\n",
        "driver = webdriver.Chrome()\n",
        "\n",
        "# Navigate to the URL\n",
        "url = 'https://secure.classmates.com/auth/login'\n",
        "driver.get(url)\n",
        "\n",
        "# Wait for elements to be visible\n",
        "wait = WebDriverWait(driver, 10)\n",
        "\n",
        "try:\n",
        "\n",
        "    # Locate and click the \"Sign in using password\" button\n",
        "    f1 = wait.until(EC.element_to_be_clickable((By.ID, \"sign-in-using-password\")))\n",
        "    f1.click()\n",
        "    time.sleep(5)  # Short delay to mimic human behavior\n",
        "\n",
        "    # Locate the username and password input fields\n",
        "    username_field = wait.until(EC.presence_of_element_located((By.ID, \"magicLogin\")))  # Replace \"magicLogin\" if incorrect\n",
        "    password_field = driver.find_element(By.ID, \"loginPassword\")  # Replace \"loginPassword\" if incorrect\n",
        "\n",
        "    # Input the credentials\n",
        "    username_field.send_keys(\"adande@gmu.edu\")  # Replace with your username\n",
        "\n",
        "    time.sleep(5)  # Short delay to mimic human behavior\n",
        "    password_field.send_keys(\"My_password\")  # Replace with your password\n",
        "\n",
        "    time.sleep(5)  # Short delay to mimic human behavior\n",
        "\n",
        "    # Locate the login button and click it\n",
        "    login_button = driver.find_element(By.ID, \"login-button\")  # Replace \"login-button\" if incorrect\n",
        "    login_button.click()\n",
        "\n",
        "    time.sleep(2)\n",
        "\n",
        "    image_elements = driver.find_elements(By.XPATH, \"//img[contains(@src, 'https://yb.cmcdn.com/yearbooks')]\")\n",
        "\n",
        "     # Regex pattern to match URLs ending with numbers before the file extension\n",
        "    pattern = re.compile(r\".*/\\d+\\.jpg$\")\n",
        "\n",
        "    valid_image_urls = [] # Only for full page images -> url ends with { page number }.jpg\n",
        "\n",
        "      # Loop through the <img> elements to check their 'src' attribute\n",
        "    for img in image_elements:\n",
        "            src = img.get_attribute(\"src\")\n",
        "            if src and pattern.match(src):  # Check if 'src' exists and matches the pattern\n",
        "                valid_image_urls.append(src)\n",
        "\n",
        "    image_url = valid_image_urls[0]\n",
        "\n",
        "    image_processor = urllib.request.build_opener() # for processing the image url and to store the image further\n",
        "\n",
        "    image_processor.addheaders=[('User-Agent','Mozilla/5.0 (Windows NT 6.1; WOW64) Chrome/36.0.1941.0 Safari/537.36')]\n",
        "\n",
        "    urllib.request.install_opener(image_processor)\n",
        "\n",
        "    # store the image file\n",
        "    image_file ='/content/sample_data/step_1_page-7.jpg'\n",
        "\n",
        "    urllib.request.urlretrieve(image_url, image_file)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0p2MKGmbKxv"
      },
      "source": [
        "I observed a pattern when i printed the image urls of page-7 ( STEP-1 implementation )\n",
        "\n",
        "full page image urls follow a pattern -\n",
        "\n",
        "https://yb.cmcdn.com/yearbooks/1/4/f/5/14f548096a10e39b9a984e8461acec86/440/ {page number}.jpg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4gSE__2yock"
      },
      "source": [
        "I have written the above code to simulate STEP 1 AND STEP 2 tasks described in the data assessment.\n",
        "\n",
        "To simulate the third step, automatic login needs to be implemented more than one time and to finish the login process, it should bypass Cloudflare Turnstile challenge. I also tried using below techniques and none of them were useful.\n",
        "\n",
        "Undetected ChromeDriver - Cannot be used because of the reason it is not compatible with the current versions of chrome/chromedrivers.\n",
        "\n",
        "Paid Proxy rotators - Couldn't help in bypassing as the website is detecting and blocking proxy IP's.\n",
        "\n",
        "SeleniumBase - Was not useful in bypassing the cloudflare challenge.\n",
        "\n",
        "So, I cannot perform the STEP 3 task, but I believe I have got strong clarity and the potential to scale up the Automation process.\n",
        "\n",
        "-> Clarity on the website working process, the problem statement, finding opportunities to apply automation.\n",
        "\n",
        "-> Scaling up the automation process may involve fully automating every task required to scrape all the yearbooks. This includes streamlining each step of the workflow to ensure efficiency and scalability. I answered my approach below to fully automating every task required to scrape all the yearbooks.\n",
        "\n",
        "Below code functions represent my approach to Step 3. I tried to write code to simulate step 3 and to automate/streamline the scraping process as much as I can.\n",
        "\n",
        "Also, I observed a pattern when i printed the image urls of page-7 ( STEP-1 implementation )\n",
        "\n",
        "full page image urls follow a pattern -\n",
        "\n",
        "https://yb.cmcdn.com/yearbooks/1/4/f/5/14f548096a10e39b9a984e8461acec86/440/ { page number }.jpg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4Fjs2IPSztE"
      },
      "source": [
        "I HAVE WRITTEN DIFFERENT AUTOMATION FUNCTIONS TO:\n",
        "\n",
        "1. SCRAPE THE IMAGE FILE GIVEN IT'S URL AND PAGE NUMBER\n",
        "\n",
        "2. SCRAPE ALL IMAGE FILES BASED ON THE GIVEN INPUT YEAR (Ex: 2009, 1998)\n",
        "\n",
        "3. SCRAPE ALL YEARBOOKS FROM THE WEBSITE \"WWW.CLASSMATES.COM\" (SINGLE RUN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YQovQDUPUYT"
      },
      "source": [
        "BELOW FUNCTION IS TO SAVE IMAGE FILE OF A PAGE USING ITS URL AND PAGE NUMBER."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKR61L4-puVh"
      },
      "outputs": [],
      "source": [
        "def save_image(page_url,page_number,year):\n",
        "      '''\n",
        "      store the image using its url\n",
        "      '''\n",
        "\n",
        "      driver.get(page_url)\n",
        "\n",
        "      # Wait for the page to load completely\n",
        "      driver.implicitly_wait(3)\n",
        "\n",
        "\n",
        "      # Check if there is an advertisement pop up display with title \"Own the 2010 Alameda High School yearbook!\"-> click the 'x' botton and continue\n",
        "      try:\n",
        "\n",
        "          # Wait until the button is clickable (max 5 seconds)\n",
        "          WebDriverWait(driver, 5).until(\n",
        "                  EC.element_to_be_clickable((By.XPATH, '//button[@id=\"ember1513\"]'))\n",
        "          )\n",
        "\n",
        "          # Locate the button using XPath\n",
        "          button = driver.find_element(By.XPATH, '//button[@id=\"ember1513\"]')\n",
        "\n",
        "          # Click the button\n",
        "          button.click()\n",
        "          print(\"Button clicked successfully!\")\n",
        "\n",
        "      except:\n",
        "          pass\n",
        "\n",
        "      try:\n",
        "\n",
        "          # Locate and click the \"Sign in using password\" button\n",
        "          f1 = wait.until(EC.element_to_be_clickable((By.ID, \"sign-in-using-password\")))\n",
        "          f1.click()\n",
        "          time.sleep(2)  # Short delay to mimic human behavior\n",
        "\n",
        "          # Locate the username and password input fields\n",
        "          username_field = wait.until(EC.presence_of_element_located((By.ID, \"magicLogin\")))  # Replace \"magicLogin\" if incorrect\n",
        "          password_field = driver.find_element(By.ID, \"loginPassword\")  # Replace \"loginPassword\" if incorrect\n",
        "\n",
        "          # Input the credentials\n",
        "          username_field.send_keys(\"adande@gmu.edu\")  # Replace with your username\n",
        "\n",
        "          time.sleep(2)  # Short delay to mimic human behavior\n",
        "          password_field.send_keys(\"Srivatsava@2001\")  # Replace with your password\n",
        "\n",
        "          time.sleep()  # Short delay to mimic human behavior\n",
        "\n",
        "          # Locate the login button and click it\n",
        "          login_button = driver.find_element(By.ID, \"login-button\")  # Replace \"login-button\" if incorrect\n",
        "          login_button.click()\n",
        "\n",
        "          time.sleep(2)\n",
        "\n",
        "          # Get the image elements and find page-image urls.\n",
        "          image_elements = driver.find_elements(By.XPATH, \"//img[contains(@src, 'https://yb.cmcdn.com/yearbooks')]\")\n",
        "\n",
        "          for image_element in image_elements:\n",
        "              image_urls = image_element.get_attribute(\"src\")\n",
        "              #image_url = image_urls[0]\n",
        "              #print(image_url)\n",
        "\n",
        "          valid_image_urls = [] # Only for full page images -> url ends with { page number }.jpg\n",
        "\n",
        "          # Regex pattern to match URLs ending with numbers before the file extension\n",
        "          pattern = re.compile(r\".*/\\d+\\.jpg$\")\n",
        "\n",
        "          # Loop through the <img> elements to check their 'src' attribute\n",
        "          for img in image_elements:\n",
        "            src = img.get_attribute(\"src\")\n",
        "            if src and pattern.match(src):  # Check if 'src' exists and matches the pattern\n",
        "                valid_image_urls.append(src)\n",
        "\n",
        "          image_url = valid_image_urls[0]\n",
        "\n",
        "          image_processor = urllib.request.build_opener() # for processing the image url and to store the image further\n",
        "\n",
        "          image_processor.addheaders=[('User-Agent','Mozilla/5.0 (Windows NT 6.1; WOW64) Chrome/36.0.1941.0 Safari/537.36')]\n",
        "\n",
        "          urllib.request.install_opener(image_processor)\n",
        "\n",
        "          # store the image file\n",
        "          image_file = f'/content/sample_data/yearbook-{year}-page_number-{page_number}.jpg'\n",
        "\n",
        "          urllib.request.urlretrieve(image_url, image_file)\n",
        "\n",
        "      except Exception as e:\n",
        "          print(f\"An error occurred: {e}\")\n",
        "\n",
        "      finally:\n",
        "        # Close the browser\n",
        "        driver.quit()    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3GkVaXeO1sN"
      },
      "source": [
        "BELOW FUNCTION TAKES INPUT YEAR TO SCRAPE ALL THE IMAGE FILES FROM THAT YEAR'S YEARBOOK."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOpeF0tbFZTX"
      },
      "outputs": [],
      "source": [
        "# Function to select the \"View\" button based on the year\n",
        "def Enter_which_year_images_you_want(year):\n",
        "    # Initialize the WebDriver (use the appropriate driver for your browser, e.g., ChromeDriver)\n",
        "    driver = webdriver.Chrome()\n",
        "\n",
        "    try:\n",
        "        # Navigate to the target webpage\n",
        "        driver.get(\"https://www.classmates.com/siteui/places/school/alameda-high-school/6994/gallery?year=2011&bypass=1\")\n",
        "\n",
        "        # Dynamically locate the year heading (e.g., <h2>2009</h2>) using the input year\n",
        "        year_heading = driver.find_element(By.XPATH, f\"//h2[text()='{year}']\")\n",
        "\n",
        "        # From the year heading, find the associated 'View' button in the same section\n",
        "        view_button = year_heading.find_element(By.XPATH, \"./following-sibling::div//a[contains(@class, 'btn btn-secondary') and contains(text(), 'View')]\")\n",
        "\n",
        "        # Click the 'View' button\n",
        "        view_button.click()\n",
        "\n",
        "        # Optionally, wait for actions to complete\n",
        "        driver.implicitly_wait(5)\n",
        "\n",
        "        # Initialize the page number\n",
        "        page_number = 1\n",
        "\n",
        "        # Start the while loop\n",
        "        while True:\n",
        "            # Format the page number with leading zeros (e.g., 0001, 0002, ...)\n",
        "            formatted_page_number = f\"{page_number:04d}\"\n",
        "\n",
        "            # Construct the URL\n",
        "            url = f\"https://yb.cmcdn.com/yearbooks/1/4/f/5/14f548096a10e39b9a984e8461acec86/440/{formatted_page_number}.jpg\"\n",
        "\n",
        "            # Check if the URL is valid by sending a request\n",
        "            response = requests.head(url)  # Use a HEAD request to check if the URL exists\n",
        "            if response.status_code == 200:  # URL is valid\n",
        "                save_image(url, page_number,year)\n",
        "                page_number += 1  # Increment the page number\n",
        "            else:\n",
        "                print(f\"No more pages found. Stopping at Page {page_number - 1}.\")\n",
        "                break  # Exit the loop if the URL is invalid\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "    finally:\n",
        "        # Close the browser\n",
        "        driver.quit()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHpOLNn_Oq0t"
      },
      "source": [
        "COMPLETE AUTOMATION APPROACH:\n",
        "\n",
        "BELOW FUNCTION IS TO SCRAPE ALL YEARBOOKS FROM \"WWW.CLASSMATES.COM\" WEBSITE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NgNeIO2ANwBc"
      },
      "outputs": [],
      "source": [
        "def scrape_all_yearbooks():\n",
        "    # Initialize the WebDriver (use the appropriate driver for your browser, e.g., ChromeDriver)\n",
        "    driver = webdriver.Chrome()\n",
        "\n",
        "    try:\n",
        "        # Navigate to the target webpage\n",
        "        driver.get(\"https://www.classmates.com/siteui/places/school/alameda-high-school/6994/gallery?year=2011&bypass=1\")\n",
        "\n",
        "        # Find all <h2> elements on the page, its website html : <h2> YEAR </h2>\n",
        "        h2_elements = driver.find_elements(By.TAG_NAME, \"h2\")\n",
        "\n",
        "        # List to store identified years\n",
        "        years = []\n",
        "\n",
        "        # Regular expression to match numeric year patterns (e.g., 1990, 2009)\n",
        "        year_pattern = re.compile(r\"^\\d{4}$\")\n",
        "\n",
        "        for h2 in h2_elements:\n",
        "            year_text = h2.text.strip()\n",
        "            if year_pattern.match(year_text):  # Check if the text matches the year pattern\n",
        "                years.append(int(year_text))\n",
        "\n",
        "        # Sort the years for processing in order\n",
        "        years = sorted(years)\n",
        "        print(f\"Identified years: {years}\")\n",
        "\n",
        "        for year in years:\n",
        "            print(f\"Processing year: {year}\")\n",
        "            Enter_which_year_images_you_want(year)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cC2AtLIJZeYN"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vln5Qh9GW_za"
      },
      "source": [
        "Despite not being able to bypass the cloudflare challenge, I used other laptop with different IP address to implement STEP 1 and STEP 2 because my IP was blocked. Though, I haven't implemented or simulated STEP 3, I have designed an approach to fully automate each and every task and scrape all the yearbook image files that are available in \"www.classmates.com\" website. My approach includes writing 3 functions, tells how much clarity I have on this task and shows the maximum potential to scale up."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6SpTg1RZfo1"
      },
      "source": [
        "TIME TAKEN FOR THIS TASK: 15 hrs approx. (I used more than 10 hrs to only find methods and techniques to bypass the bot security verification challenge)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
